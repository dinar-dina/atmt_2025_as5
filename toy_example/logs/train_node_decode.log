[2025-12-05 01:51:05] COMMAND: translate.py --beam-size 5 --alpha 0.7 --input toy_example/data/raw/test.cz --src-tokenizer toy_example/tokenizers/cz-bpe-1000.model --tgt-tokenizer toy_example/tokenizers/en-bpe-1000.model --checkpoint-path toy_example/checkpoints/checkpoint_best.pt --output toy_example/output_node.txt --max-len 100 --decode-mode node --bleu --reference toy_example/data/raw/test.en
[2025-12-05 01:51:05] Arguments: {'cuda': False, 'data': 'toy_example/data/prepared/', 'source_lang': 'cz', 'target_lang': 'en', 'src_tokenizer': 'toy_example/tokenizers/cz-bpe-1000.model', 'tgt_tokenizer': 'toy_example/tokenizers/en-bpe-1000.model', 'max_tokens': None, 'batch_size': 1, 'train_on_tiny': False, 'arch': 'transformer', 'max_epoch': 10, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'max_length': 300, 'log_file': 'toy_example/logs/train_node_change_decode.log', 'save_dir': 'toy_example/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'ignore_checkpoints': True, 'encoder_dropout': 0.1, 'decoder_dropout': 0.1, 'dim_embedding': 256, 'attention_heads': 4, 'dim_feedforward_encoder': 1024, 'dim_feedforward_decoder': 1024, 'max_seq_len': 100, 'n_encoder_layers': 3, 'n_decoder_layers': 3, 'encoder_embed_path': None, 'decoder_embed_path': None, 'seed': 42, 'input': 'toy_example/data/raw/test.cz', 'checkpoint_path': 'toy_example/checkpoints/checkpoint_best.pt', 'output': 'toy_example/output_node.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 0.7, 'bleu': True, 'reference': 'toy_example/data/raw/test.en', 'decode_mode': 'node'}
[2025-12-05 01:51:06] Loaded a model from checkpoint toy_example/checkpoints/checkpoint_best.pt
[2025-12-05 01:51:41] Wrote 100 lines to toy_example/output_node.txt
[2025-12-05 01:51:41] Translation completed in 34.99 seconds
BLEU score: 0.51