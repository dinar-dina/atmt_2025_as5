[2025-12-04 23:57:19] COMMAND: translate.py --beam-size 3 --input toy_example/data/raw/test.cz --src-tokenizer toy_example/tokenizers/cz-bpe-1000.model --tgt-tokenizer toy_example/tokenizers/en-bpe-1000.model --checkpoint-path toy_example/checkpoints/checkpoint_best.pt --output toy_example/output_3.txt --max-len 100
[2025-12-04 23:57:19] Arguments: {'cuda': False, 'data': 'toy_example/data/prepared/', 'source_lang': 'cz', 'target_lang': 'en', 'src_tokenizer': 'toy_example/tokenizers/cz-bpe-1000.model', 'tgt_tokenizer': 'toy_example/tokenizers/en-bpe-1000.model', 'max_tokens': None, 'batch_size': 1, 'train_on_tiny': False, 'arch': 'transformer', 'max_epoch': 10, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'max_length': 300, 'log_file': 'toy_example/logs/train_b3.log', 'save_dir': 'toy_example/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'ignore_checkpoints': True, 'encoder_dropout': 0.1, 'decoder_dropout': 0.1, 'dim_embedding': 256, 'attention_heads': 4, 'dim_feedforward_encoder': 1024, 'dim_feedforward_decoder': 1024, 'max_seq_len': 100, 'n_encoder_layers': 3, 'n_decoder_layers': 3, 'encoder_embed_path': None, 'decoder_embed_path': None, 'seed': 42, 'input': 'toy_example/data/raw/test.cz', 'checkpoint_path': 'toy_example/checkpoints/checkpoint_best.pt', 'output': 'toy_example/output_3.txt', 'max_len': 100, 'beam_size': 3, 'alpha': 0.7, 'bleu': False, 'reference': None}
[2025-12-04 23:57:19] Loaded a model from checkpoint toy_example/checkpoints/checkpoint_best.pt
[2025-12-04 23:57:35] Wrote 100 lines to toy_example/output_3.txt
[2025-12-04 23:57:35] Translation completed in 16.06 seconds
