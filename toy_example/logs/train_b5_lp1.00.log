[2025-12-05 00:19:17] COMMAND: translate.py --beam-size 5 --input toy_example/data/raw/test.cz --src-tokenizer toy_example/tokenizers/cz-bpe-1000.model --tgt-tokenizer toy_example/tokenizers/en-bpe-1000.model --checkpoint-path toy_example/checkpoints/checkpoint_best.pt --output toy_example/output_b5_a1.txt --max-len 100 --alpha 1.0
[2025-12-05 00:19:17] Arguments: {'cuda': False, 'data': 'toy_example/data/prepared/', 'source_lang': 'cz', 'target_lang': 'en', 'src_tokenizer': 'toy_example/tokenizers/cz-bpe-1000.model', 'tgt_tokenizer': 'toy_example/tokenizers/en-bpe-1000.model', 'max_tokens': None, 'batch_size': 1, 'train_on_tiny': False, 'arch': 'transformer', 'max_epoch': 10, 'clip_norm': 4.0, 'lr': 0.0003, 'patience': 3, 'max_length': 300, 'log_file': 'toy_example/logs/train_b5_lp1.00.log', 'save_dir': 'toy_example/checkpoints/', 'restore_file': 'checkpoint_last.pt', 'save_interval': 1, 'no_save': False, 'epoch_checkpoints': False, 'ignore_checkpoints': True, 'encoder_dropout': 0.1, 'decoder_dropout': 0.1, 'dim_embedding': 256, 'attention_heads': 4, 'dim_feedforward_encoder': 1024, 'dim_feedforward_decoder': 1024, 'max_seq_len': 100, 'n_encoder_layers': 3, 'n_decoder_layers': 3, 'encoder_embed_path': None, 'decoder_embed_path': None, 'seed': 42, 'input': 'toy_example/data/raw/test.cz', 'checkpoint_path': 'toy_example/checkpoints/checkpoint_best.pt', 'output': 'toy_example/output_b5_a1.txt', 'max_len': 100, 'beam_size': 5, 'alpha': 1.0, 'bleu': False, 'reference': None}
[2025-12-05 00:19:17] Loaded a model from checkpoint toy_example/checkpoints/checkpoint_best.pt
[2025-12-05 00:19:55] Wrote 100 lines to toy_example/output_b5_a1.txt
[2025-12-05 00:19:55] Translation completed in 37.73 seconds
